{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "import pandas as pd\n",
    "from minisom import MiniSom  \n",
    "import math\n",
    "import ipynb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# Import custom functions from seperate workbook\n",
    "from ipynb.fs.full.helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization\n",
    "def data_prep(data):\n",
    "    data_normal = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "    data_normal = data_normal.values\n",
    "    return(data_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['area', 'perimeter', 'compactness', 'length_kernel', 'width_kernel',\n",
    "                   'asymmetry_coefficient', 'length_kernel_groove', 'target']\n",
    "\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt', \n",
    "                    names=columns, \n",
    "                   sep='\\t+', engine='python')\n",
    "\n",
    "labels = data['target'].values\n",
    "label_names = {1:'Kama', 2:'Rosa', 3:'Canadian'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_first = data[data.columns[0:6]]\n",
    "data_last = data[data.columns[4:6]]\n",
    "\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(data_first, labels, stratify=labels)\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(data_last, labels, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have to flatten our data so we are able to feed it to the SOM\n",
    "x_test_r = data_prep(X_test_f)\n",
    "x_train_r = data_prep(X_train_f)\n",
    "\n",
    "x_test_o = data_prep(X_test_l)\n",
    "x_train_o = data_prep(X_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x_test_r = np.array([[i] for i in x_test_r])\n",
    "# x_train_r = np.array([[i] for i in x_train_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "som = create_train_som(x_test_r, 6)\n",
    "som_2 = create_train_som(x_test_o, x_test_o.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.76      0.81        17\n",
      "           2       0.82      1.00      0.90        18\n",
      "           3       1.00      0.89      0.94        18\n",
      "\n",
      "    accuracy                           0.89        53\n",
      "   macro avg       0.89      0.88      0.88        53\n",
      "weighted avg       0.90      0.89      0.89        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_f, classify(som, x_test_r, x_train_r, y_train_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.72      0.79        18\n",
      "           2       0.74      1.00      0.85        17\n",
      "           3       0.87      0.72      0.79        18\n",
      "\n",
      "    accuracy                           0.81        53\n",
      "   macro avg       0.82      0.81      0.81        53\n",
      "weighted avg       0.83      0.81      0.81        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_l, classify(som_2, x_test_o, x_train_o, y_train_l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so what can I do, I can run each feature through a SOM train it and then get the output, showing the training times, the accuracy and etc. Now the next question becomes what dataset should I be using? Obviously one with multiple features. Ok once we have all those base level features evaluated I will construct a modular SOM based off the input SOM's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
