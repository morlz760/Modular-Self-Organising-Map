{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "import pandas as pd\n",
    "from minisom import MiniSom  \n",
    "import math\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16a50ab38>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 7777 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
       "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
       "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
       "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
       "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
       "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
       "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
       "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
       "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
       "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
       "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
       "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
       "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,v=eig(x_train[1])\n",
    "v.shape\n",
    "# print('E-vector', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morley_reshape(data):\n",
    "    res = np.reshape(data, (data.shape[0], data.shape[1]*data.shape[2]))\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = morley_reshape(x_test)\n",
    "x_train = morley_reshape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = MiniSom(25, 25, 784, sigma=0.3, learning_rate=0.5) # initialization of 6x6 SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      " [ 100 / 100 ] 100% - 0:00:00 left "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morleypemberton/.pyenv/versions/3.7.3/lib/python3.7/site-packages/minisom.py:486: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return sqrt(-2 * cross_term + input_data_sq + weights_flat_sq.T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " quantization error: 2121.099181327279\n",
      "...ready!\n"
     ]
    }
   ],
   "source": [
    "som.random_weights_init(x_train)\n",
    "print(\"Training...\")\n",
    "som.train_random(x_train,100, verbose=True) # training with 100 iterations\n",
    "print(\"...ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28738649, 0.44580042, 0.42486826, 0.51179413, 0.59226887,\n",
       "        0.55257446, 0.54371841, 0.53293283, 0.47119307, 0.53658542,\n",
       "        0.48032691, 0.45801623, 0.50794173, 0.56170547, 0.48222696,\n",
       "        0.48920175, 0.48896094, 0.46791908, 0.49926286, 0.46464569,\n",
       "        0.50051418, 0.50171845, 0.48940694, 0.43343068, 0.24724218],\n",
       "       [0.47114427, 0.75681028, 0.7375359 , 0.74142457, 0.74786475,\n",
       "        0.81737329, 0.90488809, 0.87600378, 0.86860935, 0.7279685 ,\n",
       "        0.75470344, 0.74911763, 0.8574174 , 0.77467864, 0.92177829,\n",
       "        0.81809606, 0.67444003, 0.73527576, 0.72800138, 0.76271738,\n",
       "        0.80696408, 0.88277774, 0.70235009, 0.80549909, 0.45075173],\n",
       "       [0.47726916, 0.74722683, 0.78931211, 0.77331044, 0.78777179,\n",
       "        0.74821918, 0.88681339, 0.96168271, 0.80507139, 0.86517822,\n",
       "        0.9112968 , 0.74603381, 0.76579623, 0.80332181, 0.74540003,\n",
       "        0.65244162, 0.68447848, 0.71949226, 0.76748783, 0.71208652,\n",
       "        0.79925673, 0.84512643, 0.74136432, 0.79077151, 0.44420015],\n",
       "       [0.48813723, 0.86190595, 0.79147542, 0.75104504, 0.72394345,\n",
       "        0.73918582, 0.81653335, 0.79807391, 0.88000877, 0.80921904,\n",
       "        0.82923417, 0.80027715, 0.74666696, 0.88070155, 0.78744062,\n",
       "        0.88734012, 0.7276525 , 0.67065863, 0.66228462, 0.76702356,\n",
       "        0.75430115, 0.82323441, 0.88863353, 0.78437697, 0.54575628],\n",
       "       [0.48764033, 0.77700269, 0.87323671, 0.76003071, 0.73705978,\n",
       "        0.73996542, 0.74230483, 0.75735937, 0.76798569, 0.78844818,\n",
       "        0.79752382, 0.81056153, 0.79479504, 0.8598581 , 0.81281563,\n",
       "        0.72870217, 0.77694237, 0.68611839, 0.77688949, 0.76053494,\n",
       "        0.79588364, 0.7690533 , 0.79925875, 0.79631515, 0.5017763 ],\n",
       "       [0.46384943, 0.75333741, 0.84608042, 0.73811212, 0.78348152,\n",
       "        0.72153917, 0.81856636, 0.77296784, 0.75191008, 0.6964613 ,\n",
       "        0.71196736, 0.80468923, 0.84974789, 0.84257696, 0.87660298,\n",
       "        0.72911272, 0.72503552, 0.72007645, 0.75087041, 0.74294316,\n",
       "        0.74744008, 0.8689835 , 0.6649166 , 0.82020771, 0.4800625 ],\n",
       "       [0.51249224, 0.82752762, 0.75240661, 0.88066055, 0.61598298,\n",
       "        0.82364633, 0.87951933, 0.78305356, 0.70861262, 0.73531636,\n",
       "        0.69905819, 0.82580783, 0.91411174, 0.75986261, 0.86178145,\n",
       "        0.81470059, 0.75942525, 0.78445286, 0.72776319, 0.74933363,\n",
       "        0.81761765, 0.76224952, 0.7075117 , 0.66948426, 0.46543495],\n",
       "       [0.45158923, 0.82217956, 0.81673907, 0.64965981, 0.75629285,\n",
       "        0.83198389, 0.82799598, 0.83059599, 0.83216711, 0.80862877,\n",
       "        0.73767523, 0.7554886 , 0.73223648, 0.72233165, 0.77836751,\n",
       "        0.74258989, 0.9517056 , 0.72514504, 0.71983348, 0.80043785,\n",
       "        0.82627465, 0.77440451, 0.77825208, 0.72336556, 0.45793859],\n",
       "       [0.44469674, 0.71031136, 0.79278713, 0.84345256, 0.76795656,\n",
       "        0.85062502, 0.82545911, 0.68987619, 0.73966301, 0.72979913,\n",
       "        0.7881701 , 0.82757307, 0.71556852, 0.6865057 , 0.69571887,\n",
       "        0.75094498, 0.70865658, 0.73073472, 0.74339838, 0.80644461,\n",
       "        0.88746479, 0.76591291, 0.71127848, 0.80801897, 0.46801377],\n",
       "       [0.42503689, 0.87272578, 0.79215102, 0.87007411, 0.78240381,\n",
       "        0.86167731, 0.65949606, 0.75909518, 0.66823811, 0.81256369,\n",
       "        0.70563052, 0.70231506, 0.84024957, 0.76815878, 0.77457826,\n",
       "        0.73313344, 0.7690143 , 0.79662678, 0.69732719, 0.8523928 ,\n",
       "        0.82919031, 0.78082325, 0.74790956, 0.74825541, 0.44965987],\n",
       "       [0.43697777, 0.69582264, 0.79641491, 0.7560916 , 0.7717912 ,\n",
       "        0.73106207, 0.73052656, 0.70937501, 0.78966943, 0.70371967,\n",
       "        0.7361017 , 0.70254133, 0.79165054, 0.82316164, 0.83760879,\n",
       "        0.93410512, 0.742672  , 0.74130399, 0.83201918, 0.71302352,\n",
       "        0.75906609, 0.74168372, 0.78311583, 0.7123315 , 0.46974319],\n",
       "       [0.47758756, 0.74041029, 0.77422625, 0.75462694, 0.68589219,\n",
       "        0.69410703, 0.7891004 , 0.78247125, 0.73720194, 0.69648001,\n",
       "        0.74875001, 0.64081403, 0.73977587, 0.85135423, 0.82110207,\n",
       "        0.77901192, 0.70752035, 0.81577881, 0.72793657, 0.71277893,\n",
       "        0.67653558, 0.79840723, 0.7730069 , 0.80363648, 0.48264001],\n",
       "       [0.53773526, 0.83102811, 0.7986687 , 0.7665653 , 0.71996483,\n",
       "        0.71701718, 0.67210684, 0.64974312, 0.6611335 , 0.70285949,\n",
       "        0.76390909, 0.74618737, 0.62117569, 0.80449688, 0.87576718,\n",
       "        0.73030384, 0.70307513, 0.74877344, 0.71909914, 0.71491165,\n",
       "        0.7243461 , 0.80513471, 0.87058561, 0.83452191, 0.47368104],\n",
       "       [0.51721158, 0.86710236, 0.86716914, 0.77127225, 0.88302079,\n",
       "        0.71690715, 0.74464323, 0.63416755, 0.65045579, 0.70265389,\n",
       "        0.76093027, 0.69915571, 0.73314011, 0.75727744, 0.81579617,\n",
       "        0.77208091, 0.78886068, 0.75981107, 0.72164389, 0.76492385,\n",
       "        0.86352021, 0.83278762, 0.72502909, 0.76894612, 0.51272286],\n",
       "       [0.50126896, 0.7763704 , 0.76839072, 0.84062258, 0.84547746,\n",
       "        0.88563937, 0.72626369, 0.67203996, 0.73643898, 0.82555296,\n",
       "        0.81467712, 0.86825487, 0.72093873, 0.88736784, 0.85778892,\n",
       "        0.7922731 , 0.76155169, 0.67064229, 0.73845054, 0.73672281,\n",
       "        0.76860185, 0.77189011, 0.70624631, 0.81835331, 0.50408009],\n",
       "       [0.49434141, 0.75187803, 0.86635944, 0.82960463, 0.91353931,\n",
       "        0.85864199, 0.88176882, 0.78512176, 0.82737995, 0.81051157,\n",
       "        0.89710008, 0.75385   , 0.77615594, 0.80038442, 0.81273592,\n",
       "        0.78937122, 0.67347842, 0.74711455, 0.64583649, 0.75376894,\n",
       "        0.73198507, 0.7322032 , 0.87300852, 0.73594869, 0.5402572 ],\n",
       "       [0.51366695, 0.79277908, 0.81157186, 0.79674772, 0.7803925 ,\n",
       "        0.93723222, 0.86309538, 0.73269553, 0.72734021, 0.7260133 ,\n",
       "        0.75406686, 0.75567805, 0.71860222, 0.68053972, 0.68853263,\n",
       "        0.76274842, 0.78503276, 0.65711886, 0.80110709, 0.76590785,\n",
       "        0.81747615, 0.77848579, 0.75978204, 0.82179253, 0.4290593 ],\n",
       "       [0.43587599, 0.83498659, 0.75260252, 0.78563967, 0.79809904,\n",
       "        0.77932551, 0.73620888, 0.74012573, 0.69231454, 0.79801065,\n",
       "        0.8599822 , 0.74322083, 0.76830054, 0.67312676, 0.76941829,\n",
       "        0.76676465, 0.77489965, 0.73280535, 0.68840801, 0.80683379,\n",
       "        0.8327201 , 0.74766755, 1.        , 0.80124195, 0.39304286],\n",
       "       [0.40860018, 0.69440273, 0.78580403, 0.81934795, 0.86681371,\n",
       "        0.91197613, 0.77419921, 0.79422667, 0.77709677, 0.77755688,\n",
       "        0.89930793, 0.73955258, 0.73222544, 0.74325068, 0.66374247,\n",
       "        0.7467196 , 0.79441268, 0.78308089, 0.72605604, 0.71878608,\n",
       "        0.78858686, 0.82135759, 0.76904369, 0.74290603, 0.42097011],\n",
       "       [0.46230422, 0.74855735, 0.83422173, 0.87619888, 0.90809878,\n",
       "        0.8531353 , 0.95094291, 0.8052651 , 0.76862998, 0.7136254 ,\n",
       "        0.68522153, 0.713824  , 0.76911576, 0.69912755, 0.76265951,\n",
       "        0.78692518, 0.77178766, 0.82347376, 0.81373045, 0.74141803,\n",
       "        0.78479433, 0.77238376, 0.72051077, 0.84345646, 0.44355809],\n",
       "       [0.46380844, 0.78547857, 0.75188449, 0.83528978, 0.85697365,\n",
       "        0.79442039, 0.72207907, 0.82404744, 0.74450357, 0.62017206,\n",
       "        0.63831417, 0.69157546, 0.74155102, 0.74169214, 0.76015009,\n",
       "        0.72972365, 0.7777104 , 0.72779711, 0.73805702, 0.69250055,\n",
       "        0.72360236, 0.85142586, 0.72957089, 0.6906247 , 0.48020978],\n",
       "       [0.51698012, 0.71552162, 0.71256348, 0.81491443, 0.77087459,\n",
       "        0.75526946, 0.72618651, 0.71352302, 0.74823955, 0.66461099,\n",
       "        0.63582079, 0.70802484, 0.81677198, 0.86482302, 0.75500368,\n",
       "        0.76965149, 0.75628181, 0.78922131, 0.81211297, 0.79855577,\n",
       "        0.79667581, 0.86584324, 0.75245759, 0.78121153, 0.47831428],\n",
       "       [0.49915786, 0.68548779, 0.70644523, 0.70663629, 0.80852687,\n",
       "        0.73518598, 0.70015356, 0.70362528, 0.81013024, 0.77049504,\n",
       "        0.81272063, 0.82284017, 0.76559698, 0.88865397, 0.88430524,\n",
       "        0.77219034, 0.77601524, 0.93134559, 0.77321769, 0.88162555,\n",
       "        0.75732349, 0.7889413 , 0.84281569, 0.76734861, 0.50612742],\n",
       "       [0.46246666, 0.71187799, 0.67894839, 0.78776222, 0.82660336,\n",
       "        0.74810614, 0.74377369, 0.72277404, 0.76062608, 0.7370446 ,\n",
       "        0.74861796, 0.75489316, 0.88233655, 0.833286  , 0.81792701,\n",
       "        0.7430882 , 0.75096962, 0.78106943, 0.8521346 , 0.76420656,\n",
       "        0.75757203, 0.714308  , 0.76358001, 0.84457095, 0.43732002],\n",
       "       [0.28557112, 0.44938951, 0.52964593, 0.46219747, 0.4551729 ,\n",
       "        0.54381633, 0.57648818, 0.44600442, 0.42813701, 0.46333988,\n",
       "        0.50745286, 0.46398033, 0.51409179, 0.57351223, 0.47087783,\n",
       "        0.40654606, 0.47610072, 0.49649094, 0.48263542, 0.49251271,\n",
       "        0.44901873, 0.49331796, 0.53712498, 0.53502208, 0.30582161]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som.distance_map().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(som, x_test, x_train, y_train):\n",
    "    \"\"\"Classifies each sample in data in one of the classes definited\n",
    "    using the method labels_map.\n",
    "    Returns a list of the same length of data where the i-th element\n",
    "    is the class assigned to data[i].\n",
    "    \"\"\"\n",
    "    winmap = som.labels_map(x_train, y_train)\n",
    "    default_class = np.sum(list(winmap.values())).most_common()[0][0]\n",
    "    result = []\n",
    "    for d in x_test:\n",
    "        win_position = som.winner(d)\n",
    "        if win_position in winmap:\n",
    "            result.append(winmap[win_position].most_common()[0][0])\n",
    "        else:\n",
    "            result.append(default_class)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       980\n",
      "           1       0.88      0.99      0.93      1135\n",
      "           2       0.92      0.86      0.89      1032\n",
      "           3       0.86      0.89      0.88      1010\n",
      "           4       0.81      0.86      0.83       982\n",
      "           5       0.88      0.83      0.85       892\n",
      "           6       0.94      0.93      0.93       958\n",
      "           7       0.88      0.85      0.86      1028\n",
      "           8       0.90      0.79      0.84       974\n",
      "           9       0.79      0.78      0.78      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, classify(som,  x_test, x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pixels_top_10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-10e015681858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpixels_top_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pixels_top_10' is not defined"
     ]
    }
   ],
   "source": [
    "pixels_top_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, should we cut up beforehnd? or slide across after? like how do we cut up the pixels\n",
    "# then we take the classifications from that? or take the winning neuron hmmm.\n",
    "\n",
    "\n",
    "# ok so we define our kernal granularity in terms of pixels, like 6X6, I want to know how this is \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we do is we create a matrix full of sub matricies. Each matrix is a sub region of our image. In the paper that Im looking at they use a kernal size of 10X10 pixels with a stride of 2 so thats what I've set below. This function takes the whole matix when its not flattened and cuts it up into 10 by 10 squares which i can then flatten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheeky bit of code I've taken from https://medium.com/analytics-vidhya/image-convolution-from-scratch-d99bf639c32a\n",
    "\n",
    "def get_sub_matrices(orig_matrix, kernel_size): \n",
    "    width = len(orig_matrix[0])\n",
    "    height = len(orig_matrix)\n",
    "    if kernel_size[0] == kernel_size[1]:\n",
    "        if kernel_size[0] > 2:\n",
    "            orig_matrix = np.pad(orig_matrix, kernel_size[0] - 2, mode='constant')\n",
    "        else: pass\n",
    "    else: pass\n",
    "    \n",
    "    giant_matrix = []\n",
    "    for i in range(0, height - kernel_size[1] + 1):\n",
    "        for j in range(0, width - kernel_size[0] + 1):\n",
    "            giant_matrix.append(\n",
    "                [\n",
    "                    [orig_matrix[col][row] for row in range(j, j + kernel_size[0])]\n",
    "                    for col in range(i, i + kernel_size[1])\n",
    "                ]\n",
    "            )\n",
    "    img_sampling = np.array(giant_matrix)\n",
    "    return img_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_kernel = np.array([[0,0,0],[0,1,0],[0,0,0]])\n",
    "identity_kernel.shape\n",
    "(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_matrix = get_sub_matrices(x_train[1], (10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my sub matricies I'll be passing them through to a number of individual SOM's. Before I do this though I needd to flatten the arrays into a single vector, maybe I should do this in the function above? Nah I dont think so, lets try keep it staged? Thay way if I want to apply some convolutions to the image, maybe instead of using the eigne vectors? I could do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function applies a kernal filter to the image, what does that mean you ask? \n",
    "Well we've got our sub regions using the get sub matrices above and using this function here we can \n",
    "i guess manipulate those sub regions to try and extract more information from them, one such example is the \n",
    "identity kernal,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_matrix(matrix_sampling, kernel_filter):\n",
    "    transform_mat = []\n",
    "    for each_mat in matrix_sampling:\n",
    "        transform_mat.append(\n",
    "            np.sum(np.multiply(each_mat, kernel_filter))\n",
    "        )\n",
    "    reshape_val = int(math.sqrt(matrix_sampling.shape[0]))\n",
    "    transform_mat = np.array(transform_mat).reshape(reshape_val, reshape_val)\n",
    "    return transform_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a function to flatten our sub matricies\n",
    "We need to write a function that takes all my sub things and flattens them then returns that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_sampled_matrix(matrix_sampling):\n",
    "    transform_mat = []\n",
    "    for each_mat in matrix_sampling:\n",
    "        transform_mat.append(\n",
    "            np.reshape(each_mat, (each_mat.shape[0], each_mat.shape[1]*each_mat.shape[2]))\n",
    "        )\n",
    "    return transform_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = flatten_sampled_matrix(sampled_matrix)\n",
    "\n",
    "sampled_matrix_flattened = morley_reshape(sampled_matrix)\n",
    "\n",
    "\n",
    "# each_mat = sampled_matrix[1]\n",
    "\n",
    "# print(each_mat.shape)\n",
    "# print(x_train[1].shape)\n",
    "# np.reshape(each_mat, (each_mat.shape[0], each_mat.shape[1]*each_mat.shape[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361, 100)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_matrix_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = get_transformed_matrix(sampled_matrix, identity_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
