{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "import pandas as pd\n",
    "from minisom import MiniSom  \n",
    "import math\n",
    "import ipynb\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This workbook defines the functions that we use in our code. Its here to keep everything nice and organised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function flattens and reshapes our data so that we can feed it to our SOM for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_reshape(data):\n",
    "    data = np.array(data)\n",
    "    res = np.reshape(data, (data.shape[0], data.shape[1]*data.shape[2]))\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extracts the egine vector values from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_egine_vectors(data):\n",
    "    extracted_vals = []\n",
    "    for each_image in data:\n",
    "        w,v=eig(each_image)\n",
    "        extracted_vals.append(\n",
    "            v\n",
    "        )\n",
    "    extracted_vals = np.array(extracted_vals)\n",
    "    return extracted_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function evaluates our SOM against our test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(som, x_test, x_train, y_train):\n",
    "    winmap = som.labels_map(x_train, y_train)\n",
    "    default_class = np.sum(list(winmap.values())).most_common()[0][0]\n",
    "    result = []\n",
    "    for d in x_test:\n",
    "        win_position = som.winner(d)\n",
    "        if win_position in winmap:\n",
    "            result.append(winmap[win_position].most_common()[0][0])\n",
    "        else:\n",
    "            result.append(default_class)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Train SOM\n",
    "This function creates a basic SOM\n",
    "\n",
    "***Variables*** \\\n",
    "x_train = training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_som(x_train, n_features):\n",
    "    \n",
    "    # Create SOM dimensions\n",
    "    som_nurons = int((math.sqrt(5*math.sqrt(n_features))))\n",
    "    print(som_nurons)\n",
    "    x = som_nurons\n",
    "    y = som_nurons\n",
    "    \n",
    "    #Create and train SOM\n",
    "    som = MiniSom(x, y, n_features, sigma=0.3, learning_rate=0.5) # initialization of 6x6 SOM\n",
    "    som.random_weights_init(x_train)\n",
    "#     print(\"Training...\")\n",
    "    som.train_random(x_train,100, verbose=False) # training with 100 iterations\n",
    "#     print(\"...ready!\")\n",
    "    return som"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Sampling Layer\n",
    "\n",
    "This function takes in the trained SOMs and the training data for a given layer. Its important to note that for the function in this specific implementation the traning data for the soms needs to be the same length, this is because for the observation we taking the results for all the somz trained on that specific one and combining them together.\n",
    "\n",
    "***Variables*** \\\n",
    "trained_som_list = a list of trained SOMs \\\n",
    "training_data_list = a list of the training data indexed in the same position as the som that was used to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sampling_layer(trained_som_list, training_data_list):\n",
    "    # create empty output list\n",
    "    int_output = []\n",
    "    \n",
    "    for n, som in enumerate(trained_som_list):\n",
    "        som_output = []\n",
    "        training_data = training_data_list[n]\n",
    "        # find each SOM value \n",
    "        winning_pos = [som.winner(d) for d in training_data[0:10]]\n",
    "        int_output.append(winning_pos)\n",
    "        \n",
    "    # Combine the winning SOM position for the given example.\n",
    "    final_output = pd.DataFrame(int_output).transpose().to_numpy()\n",
    "    return(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Coordinants\n",
    "This function convers the coordinants of a SOM with a known grid size into a numerical value suchh that it can be passed onto thhe next som\n",
    "\n",
    "***Variables*** \\\n",
    "coordinants = the X,Y coordinants of the winning som for a given training example \\\n",
    "som_y_size = the maximum value of the y value of the SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coordinants(coordinants, som_y_size):\n",
    "    x = coordinants[0]\n",
    "    y = coordinants[1]\n",
    "    unique_num = x * som_y_size + y\n",
    "    return(unique_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Dictionary\n",
    "\n",
    "This function filters our dictionary to only return the patchs for a given image. \n",
    "\n",
    "**Variables** \\\n",
    "d = the dicitonary to be filtered\\\n",
    "filter_string = the value the dict will be filtered on\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict(d, filter_string):\n",
    "    for key, val in d.items():\n",
    "        values = key.split(\"-\")\n",
    "        image_index = values[0]\n",
    "        if filter_string != image_index:\n",
    "            continue\n",
    "        yield key, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
